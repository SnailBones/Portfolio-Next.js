# Prism Escape

In September 2019, I started work at _Electric Playhouse_, where I built sensor-power games played with the body. _Prism Escape_, also known as _Space Runner_ was my first game for a three-walled pod and the **first game at Electric Playhouse to display a virtual 3D environment**.

I worked to achieve the mission of Electric Playhouse to build games for everyone, not just traditional "gamers" or any other limitations of age, experience, or language. Furthering this mission meant prioritizing many kinds of accessibility—games needed to be playable by visitors of all sizes and various abilities. What's more, I quickly discovered that visitors were easily confused by the novel medium of controller-free games. Without prior experiences to reference or an understanding of how our sensors worked, they had difficulty figuring out how to interact with our games. On the first demo night of the game that would become _Prism Escape_, several visitors interacted with the game _without realizing that it was a game at all_!

Well, back to the drawing board. Since _accessibility to non-English speakers and pre-literate children was a priority_, a text tutorial would be an insufficient solution. Instead, I needed to work with a wordless visual language that would provide grounding, familiar clues—to point the visitors to recognize the game and provide pointers at how it might be played.

One of many techniques that I learned to do this was to borrow symbols from other media, providing a hint of something familiar in my alien-feeling games. For maximum accessibility, I reached to the most widely played and recognized games—mobile games and classic video games—for a design language that would be broadly recognized. In the case of _Prism Escape_, I borrowed the game's premise and aesthetics from the popular endless runner genre, later adding influence from classic racing games.

In both genres, the player guides a character around obstacles as far (in endless runners) or fast (in racing games) as possible, using a joystick, arrow keys, or a touchscreen. Electric Playhouse games have no controller—instead, **the input is a "depth mask," effectively the players' shadow** created by flattening the sensors' point cloud. Sensors detect a player's body (or other objects) throughout the whole game area, but at each particular point their resolution is low, and noise is abundant. As a result, the input is anything but the simple, discrete input of most human-computer interfaces. There's no easy way to tell an avatar to move left or right.

Instead, **I conceived of using the player's depth mask as their "avatar"**—considering a collision as occurring when the player's shadow sufficiently overlaps with an obstacle. In my first attempt, I converted the 1-bit image texture to a JavaScript array and counted the number of pixels where the depth mask intersected the obstacle. This proved far too slow for a game—I needed to port the behavior to the GPU.

In _Prism Escape_ and my other Electric Playhouse games, game logic runs in JavaScript on the CPU, while depth is manipulated in GLSL shaders—which harness the extreme parallelization of GPUs to perform intense image processing operations that would grind the CPU to a halt. Unfortunately, moving data from the GPU to the CPU is a slow operation and critical bottleneck. Previous games at Electric Playhouse featured circular "colliders," implemented through a Euclidean distance transform and sampling at a single point. For _Prism Escape_, I needed rectangular colliders of different sizes to represent the rectangular prism obstacles. Given the large and varying prisms, **how could I accurately detect collisions without sacrificing game performance?**

I developed a custom shader solution to this problem, taking advantage of the fact that GPU hardware is optimized for resampling textures. My algorithm "cuts" out the depth mask in the collider's area by copying it to a new texture, then **iteratively resamples this texture onto textures of half the dimensions**. Hardware optimization makes this a fast and error-free operation. Once the data has been resampled on to a texture containing only a single pixel, its value represents the average percent of collision across the entire rectangle. **The CPU then reads just this single pixel**, allowing for accurate collision detection with minimal latency and a framerate of 60fps.

Unfortunately, in my initial three life endless-runner prototype, collisions still felt unpredictable. Because of the countless shapes that the player's body (or bodies) could take, exacerbated by noise and latency of the sensors, _any_ threshold for collision would cause seemingly false hits or false misses if not both. Grazing an arm or foot would sometimes trigger a loss, which felt unpredictable and unfair to players.

Given the "soft" nature of position data, I realized that I could mitigate this perceived unfairness with a soft or continuous penalty. I made a change to the game's mechanics: instead of losing a fixed number of lives, **collisions now slowed the player**. The amount slowed depends on how much they had overlapped the prism: a direct hit has a greater impact than a slight graze, requiring unprecedented collider precision.

To allow the player to regain speed, I added a **procedurally generated pathway of arrows** that weaves their way around the prisms. Colliding with an arrow provides a small boost. Crucially, the path also provides clear guidance that the player should try to avoid the prisms. This change also mitigated a physical accessibility challenge—unlike my initial drafts where the game moved forward at a constant speed, **the game's speed now adapted to the player's skill level**. A game that had been trivial for its masters and insurmountably hard for nearly everyone else, became accessible and fun for first-time players and competitive “pinball wizards” alike.

After experimenting with several game end scenarios, I settled on one inspired by classic racing games: above the horizon, a timer ticks down. The player can gain additional time from clocks collected at checkpoints along the road, but the game ends if they fail to reach one in time. Combined with the slowdown mechanic, this heightened suspense while also adding a greater element of predictability—and **perceived fairness**—to the game's end. Combined with my shader effects and sounds by Chris Alires, the slowdown also adds an illusion of physical mass to the prisms.

Implementing the Trompe-l'œil 3D effect proved an interesting challenge, particularly aligning game components in both HTML canvas and GLSL shaders. The company’s framework at the time did not support external libraries such as Three.js, so **I coded one-point perspective from scratch.** Particularly challenging was implementing a perspective transform for the cast shadow seen at the base of the player’s "ghost," though my effort payed off with the clarity to game position that it provides.

I later rewrote my 3D framework and collision system alike as modules within an **[open-source JavaScript library](https://github.com/SnailBones/physalis)**, enabling me and my team to draw from the features I'd already developed to more quickly build performant and feature-rich games.

_Prism Escape_ is best played by one player at a time, but has proven to be something of a spectator sport, drawing crowds and cameras. The test of physical agility, suspense, and the parallax New Mexico-inspired scenery by artist Thomas Herrara make it almost as fun to watch as it is to play. Besides, you'll need to catch your breath after giving it a go!

If you're in **Albuquerque, NM** or **Las Vegas, NV**, head to the local [Electric Playhouse](https://www.electricplayhouse.com) and find out if you're the next _Prism Escape_ wizard!
